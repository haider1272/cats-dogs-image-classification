{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":4748798,"sourceType":"datasetVersion","datasetId":2716794}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zulqarnain11/cats-vs-dogs-classifier-efficientnet?scriptVersionId=291692733\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"border-radius: 30px 0 30px 0px; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">\n        üê±üê∂ Cats & Dogs Classifier: ü•á High Accuracy with EfficientNet!\n    </h1>\n</div>\n","metadata":{"id":"6BjEvN7BSYQZ"}},{"cell_type":"markdown","source":"## 1| Problem Statement\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n\n<p>Given a dataset of cat and dog images, the task is to develop a machine learning model that can accurately classify between cats and dogs in an image.</p>\n</div>\n","metadata":{"id":"11EvygsQS4bS"}},{"cell_type":"markdown","source":"## 2| About The Data\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n\n<ul>\n<li>Dataset contains 557 cat and dog images for training, 140 images for testing.</li>\n<li>Images vary in size, JPEG format.</li>\n<li>The goal is to build a binary classifier using deep learning.</li>\n</ul>\n</div>\n","metadata":{"id":"aqvZwtnHS7MS"}},{"cell_type":"markdown","source":"## 3| About Dataset\n<div style=\"font-size:18px; line-height:1.6; color:#333;\">\n<p>This dataset contains over 1000 images of cats and dogs scraped from Google Images. The task is to build a model that can classify between cats and dogs accurately.</p>\n<ul style=\"font-size:18px;>\n<li>Image sizes vary from roughly 100x100 pixels to 2000x1000 pixels.</li>\n<li>All images are in JPEG format.</li>\n<li>Duplicates have been removed.</li>\n</ul>\n</div>\n","metadata":{"id":"OBLVTddTSbnI"}},{"cell_type":"markdown","source":"## 4| Import Libraries","metadata":{"id":"V8Y4nhkhS-E2"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport kagglehub\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")  \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\n","metadata":{"id":"5ZZvG7GosqS4","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:21.906521Z","iopub.execute_input":"2026-01-13T17:13:21.907307Z","iopub.status.idle":"2026-01-13T17:13:21.912244Z","shell.execute_reply.started":"2026-01-13T17:13:21.907278Z","shell.execute_reply":"2026-01-13T17:13:21.911648Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5| Loading Dataset\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n<p>Download and prepare the Cats and Dogs dataset for training and validation.</p>\n</div>\n","metadata":{"id":"mXJ4OMprTAf8"}},{"cell_type":"code","source":"class Config:\n    def __init__(self):\n        self.image_size = (224, 224)\n        self.batch_size = 32\n        self.epochs = 50\n        self.autotune = tf.data.AUTOTUNE\n\nconfig = Config()\n","metadata":{"id":"hmLvIxKKtUc0","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:21.913524Z","iopub.execute_input":"2026-01-13T17:13:21.913895Z","iopub.status.idle":"2026-01-13T17:13:21.933107Z","shell.execute_reply.started":"2026-01-13T17:13:21.913873Z","shell.execute_reply":"2026-01-13T17:13:21.932519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir='/kaggle/input/cats-and-dogs-image-classification/train'\nval_dir='/kaggle/input/cats-and-dogs-image-classification/test'\n\ntrain_ds = image_dataset_from_directory(\n    train_dir,\n    image_size=config.image_size,\n    batch_size=config.batch_size,\n    shuffle=True,\n\n)\n\nval_ds = image_dataset_from_directory(\n    val_dir,\n    image_size=config.image_size,\n    batch_size=config.batch_size,\n\n\n)\n\nclass_names = train_ds.class_names\nprint(\"Classes:\", class_names)\n","metadata":{"id":"k8zbn4citjcd","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:21.934416Z","iopub.execute_input":"2026-01-13T17:13:21.934726Z","iopub.status.idle":"2026-01-13T17:13:22.643062Z","shell.execute_reply.started":"2026-01-13T17:13:21.934705Z","shell.execute_reply":"2026-01-13T17:13:22.642329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Train size: {len(train_ds)}\")\nprint(f\"Test size: {len(val_ds)}\")","metadata":{"id":"RosU2t5CLOhe","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:22.64396Z","iopub.execute_input":"2026-01-13T17:13:22.644221Z","iopub.status.idle":"2026-01-13T17:13:22.648988Z","shell.execute_reply.started":"2026-01-13T17:13:22.644186Z","shell.execute_reply":"2026-01-13T17:13:22.648281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y))\nval_ds   = val_ds.map(lambda x, y: (preprocess_input(x), y))\n\n\ntrain_ds = train_ds.prefetch(config.autotune)\nval_ds    = val_ds.prefetch(config.autotune)\n","metadata":{"id":"-5wK5LfNu8RJ","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:22.650601Z","iopub.execute_input":"2026-01-13T17:13:22.650881Z","iopub.status.idle":"2026-01-13T17:13:22.697259Z","shell.execute_reply.started":"2026-01-13T17:13:22.650852Z","shell.execute_reply":"2026-01-13T17:13:22.696506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor images,labels in train_ds.take(1):\n    for i in range(9):\n        ax=plt.subplot(3,3,i+1)\n        plt.imshow((images[i]).numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")\n\n","metadata":{"id":"PCoQzBufvkam","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:22.69817Z","iopub.execute_input":"2026-01-13T17:13:22.698427Z","iopub.status.idle":"2026-01-13T17:13:23.455974Z","shell.execute_reply.started":"2026-01-13T17:13:22.698406Z","shell.execute_reply":"2026-01-13T17:13:23.455066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6| Data Augmentation\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n<p>Apply random flips, rotations, and zooms to increase dataset diversity.</p>\n</div>\n","metadata":{"id":"DP03k-TFTOiD"}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.2),\n    layers.RandomZoom(0.2),\n])\n","metadata":{"id":"YM21961L8LvJ","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:23.457376Z","iopub.execute_input":"2026-01-13T17:13:23.458156Z","iopub.status.idle":"2026-01-13T17:13:23.471666Z","shell.execute_reply.started":"2026-01-13T17:13:23.45811Z","shell.execute_reply":"2026-01-13T17:13:23.47104Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7| Build Model\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n<p>Using EfficientNetB0 as base, followed by pooling, dropout, and dense layers.</p>\n</div>\n","metadata":{"id":"WlDWcbWfTWP6"}},{"cell_type":"code","source":"base_model = EfficientNetB0(\n    weights=\"imagenet\",\n    include_top=False,\n    input_shape=(224, 224, 3)\n)\n\nbase_model.trainable = False\n","metadata":{"id":"HpbLztrjwk4V","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:23.472665Z","iopub.execute_input":"2026-01-13T17:13:23.47292Z","iopub.status.idle":"2026-01-13T17:13:24.42872Z","shell.execute_reply.started":"2026-01-13T17:13:23.472899Z","shell.execute_reply":"2026-01-13T17:13:24.427937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    data_augmentation,\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.2),\n    layers.Dense(256, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\")\n])\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()\n","metadata":{"id":"k_alAAAVwzZ6","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:24.42975Z","iopub.execute_input":"2026-01-13T17:13:24.430043Z","iopub.status.idle":"2026-01-13T17:13:24.459167Z","shell.execute_reply.started":"2026-01-13T17:13:24.430012Z","shell.execute_reply":"2026-01-13T17:13:24.458488Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8| Train Model\n<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n<p>Use EarlyStopping to prevent overfitting.</p>\n</div>\n","metadata":{"id":"cegVa8YqTbBb"}},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=3,\n    restore_best_weights=True\n)\nhistory = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=config.epochs,\n        callbacks=[early_stopping]\n    )\n\n","metadata":{"id":"zufza2qdxFLl","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:24.460135Z","iopub.execute_input":"2026-01-13T17:13:24.46063Z","iopub.status.idle":"2026-01-13T17:13:47.165026Z","shell.execute_reply.started":"2026-01-13T17:13:24.460602Z","shell.execute_reply":"2026-01-13T17:13:47.163927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9|  Results\n\n","metadata":{"id":"6uAgMNxUTeH8"}},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train')\nplt.plot(history.history['val_accuracy'], label='Val')\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train')\nplt.plot(history.history['val_loss'], label='Val')\nplt.title(\"Loss\")\nplt.legend()\n\nplt.show()\n","metadata":{"id":"0Zd7a_ll1C3F","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:47.167214Z","iopub.execute_input":"2026-01-13T17:13:47.167502Z","iopub.status.idle":"2026-01-13T17:13:47.40794Z","shell.execute_reply.started":"2026-01-13T17:13:47.167479Z","shell.execute_reply":"2026-01-13T17:13:47.407312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"font-size:18px; line-height:1.6; margin-bottom:10px;\">\n<h3>9. Confusion Matrix & Classification Report</h3>\n</div>\n","metadata":{"id":"EF1XjkY1TgpU"}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nfor images, labels in val_ds.take(1):\n    preds = np.argmax(model.predict(images), axis=1)\n\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow((images[i]).numpy().astype(\"uint8\"))\n        color = \"green\" if preds[i] == labels[i] else \"red\"\n        plt.title(\n            f\"Pred: {class_names[preds[i]]}\\nActual: {class_names[labels[i]]}\",\n            color=color,\n            fontsize=9\n        )\n        plt.axis(\"off\")\n\nplt.show()\n","metadata":{"id":"at5BgDZH2muV","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:14:35.933904Z","iopub.execute_input":"2026-01-13T17:14:35.934197Z","iopub.status.idle":"2026-01-13T17:14:36.792818Z","shell.execute_reply.started":"2026-01-13T17:14:35.934173Z","shell.execute_reply":"2026-01-13T17:14:36.791815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Collect true labels and predictions\ny_true = []\ny_pred = []\n\nfor images, labels in val_ds:\n    preds = np.argmax(model.predict(images, verbose=0), axis=1)  # silent predictions\n    y_true.extend(labels.numpy())\n    y_pred.extend(preds)\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n\n\n","metadata":{"id":"us7xVWSRQtT2","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:50.165158Z","iopub.execute_input":"2026-01-13T17:13:50.165454Z","iopub.status.idle":"2026-01-13T17:13:53.198054Z","shell.execute_reply.started":"2026-01-13T17:13:50.16543Z","shell.execute_reply":"2026-01-13T17:13:53.197325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üéØ Conclusion\n<div style=\"border-radius: 20px; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0,0,0,0.2); margin-top:20px;\">\n<h2 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0,0,0,0.5); font-weight:bold;\">\n</h2>\n<p style=\"color:white;\">\nWe successfully trained a binary classifier to distinguish cats and dogs using EfficientNetB0. Early stopping helped prevent overfitting and achieved high accuracy on the validation set.\n</p>\n</div>\n","metadata":{"id":"MquwFRjzTmSi"}}]}